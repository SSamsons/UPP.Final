```markdown
# Система сбора контактов организаций

MVC-приложение на платформе Spring Boot, предназначенное для автоматического извлечения контактных данных компаний. Система анализирует веб-страницы и бизнес-каталоги, собирая телефоны, электронную почту и физические адреса.

**Технологический стек**: многопоточная обработка с использованием кастомного пула потоков, ForkJoinPool, планировщики задач @Scheduled и ScheduledExecutorService, асинхронные HTTP-клиенты (WebFlux/WebClient, RestTemplate, OpenFeign), встраиваемая СУБД H2 с JPA, потокобезопасные коллекции и параллельные потоки данных.

## 1. Системные требования

Для корректной работы необходимо:
- Среду выполнения Java (JDK) версии 11 или новее
- Систему сборки Maven 3.8 и выше
- Windows PowerShell (для выполнения примеров команд)

## 2. Инструкция по запуску

Откройте терминал PowerShell в директории с исходным кодом и выполните одну из команд.

### Способ A (непосредственный запуск через Maven-плагин):
```powershell
mvn spring-boot:run
```

### Способ B (предварительная сборка JAR-файла):
```powershell
mvn -U -DskipTests clean package
java -jar target/company-crawler-1.0.0.jar
```

После успешного запуска веб-интерфейс будет доступен по адресу: `http://localhost:8080`.

**Завершение работы**: в активном терминале с работающим сервером нажмите сочетание клавиш Ctrl+C.

## 3. Тестирование функциональности (REST API)

Для проверки API откройте дополнительное окно PowerShell, оставив сервер работать.

### 3.1. Инициализация процесса сбора данных
- Конечная точка: `POST /api/crawler/start`
- Формат тела запроса: JSON-массив начальных адресов

```powershell
$urls = @("https://2gis.ru", "https://yandex.ru/maps", "https://example.org")
$body = $urls | ConvertTo-Json -Compress
Invoke-RestMethod -Method Post -Uri "http://localhost:8080/api/crawler/start" -Body $body -ContentType "application/json"
```

Ожидаемый ответ от сервера:
```json
{
  "taskId": "уникальный-идентификатор-задания",
  "message": "Запущен процесс сбора данных"
}
```

### 3.2. Получение статуса выполнения
- Конечная точка: `GET /api/crawler/status/{идентификаторЗадания}`

```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/crawler/status/уникальный-идентификатор-задания"
```

**Примечание**: используйте фактический идентификатор задания, полученный на предыдущем шаге. Идентификаторы становятся неактуальными после перезапуска сервера.

### 3.3. Извлечение результатов
- Конечная точка: `GET /api/data/answer`
- Параметры запроса:
  - `page`, `size` — управление разбивкой на страницы
  - `search` — необязательный фильтр по названию, сайту, адресу или контактной информации

```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/data/answer?page=0&size=10&search=it"
```

### Дополнительные возможности API

**Сортированный перечень компаний:**
```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/data/companies?search=&sortBy=name&ascending=true"
```

**Поиск по номеру телефона:**
```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/data/companies/phone/81234567890"
```

**Поиск по адресу электронной почты:**
```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/data/companies/email/info@example.org"
```

**Служебные конечные точки:**
- `GET /api/crawler/stats` — статистические показатели работы системы
- `GET /api/crawler/active-tasks` — перечень активных задач

## 4. Доступ к базе данных H2

Для прямого взаимодействия с базой данных:
- Перейдите по адресу: `http://localhost:8080/h2-console`
- Параметры подключения:
  - **JDBC URL**: `jdbc:h2:file:./data/crawlerdb`
  - **Пользователь**: `sa`
  - **Пароль**: `password`

Основная таблица для хранения данных: `companies`

## 5. Планирование задач

В системе реализовано два механизма планирования:
- Аннотация **@Scheduled** — автоматический ежедневный запуск в 2:00
- **ScheduledExecutorService** — периодический запуск каждые 30 минут

Для тестирования планировщиков можно использовать ручной запрос из раздела 3.1.

## 6. Файл конфигурации

Основные параметры настройки расположены в файле `src/main/resources/application.properties`:
- Номер порта и контекст приложения
- Настройки подключения к H2 и JPA
- Пути сохранения лог-файлов
- Базовый URL для прокси-сервиса через Feign

## 7. Рекомендации по работе в PowerShell

**Корректное отображение кириллицы:**
```powershell
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
```

**Перенос длинных команд:** используйте обратный апостроф `` ` `` в конце строки.

**Просмотр неформатированного JSON:**
```powershell
Invoke-RestMethod -Uri "http://localhost:8080/api/data/companies?search=&sortBy=name&ascending=true" | ConvertTo-Json -Depth 6
```

## 8. Возможные проблемы и способы их решения

| Проблема | Вероятная причина | Способ устранения |
|----------|-------------------|-------------------|
| **Ошибка 400 при POST /start** | Неверный формат передаваемых данных | Убедитесь, что тело запроса представляет собой валидный JSON-массив |
| **Ошибка 404 для корневого пути `/`** | Отсутствие контроллера для корневой страницы | Используйте исключительно API-эндпоинты с префиксом `/api/` |
| **Сбои при запуске через `spring-boot:run`** | Проблемы с плагином Maven | Воспользуйтесь явным указанием версии плагина или соберите JAR-файл |
| **Отсутствие данных в результатах** | Блокировка запросов сетевыми фильтрами | Проверьте работу с реальными сайтами компаний, убедитесь в отсутствии ограничений прокси |

## 9. Реализованный функционал

- Механизм обхода веб-страниц с интеллектуальным извлечением контактов
- Потокобезопасные структуры хранения данных и управляемый пул потоков
- Параллельная обработка информации с использованием ForkJoinPool и parallelStream
- Два независимых планировщика выполнения задач
- Хранение информации во встраиваемой БД H2 через Spring Data JPA
- Комбинация WebFlux, RestTemplate и OpenFeign для сетевых операций
- Полноценный набор REST-эндпоинтов для управления процессом

## 10. Система мониторинга производительности

### Интеграция с Micrometer и Prometheus

Приложение оснащено системой сбора метрик через Micrometer с поддержкой формата Prometheus.

**Доступные точки мониторинга:**
- Метрики в формате Prometheus: `http://localhost:8080/actuator/prometheus`
- Общий перечень метрик: `http://localhost:8080/actuator/metrics`
- Проверка состояния системы: `http://localhost:8080/actuator/health`

**Регистрируемые показатели:**
- Время выполнения операций парсинга
- Количество успешно обработанных страниц
- Статистика возникающих ошибок
- Объем данных, сохраненных в базе
- Количество посещенных URL-адресов
- Временные характеристики сетевых операций и операций с БД

### Запуск с расширенным мониторингом

**Для Windows:**
```powershell
.\scripts\start-with-monitoring.bat
```

**Для Linux/Mac:**
```bash
chmod +x scripts/start-with-monitoring.sh
./scripts/start-with-monitoring.sh
```

Данные скрипты активируют:
- Подробное логирование сборки мусора
- JMX для подключения VisualVM
- Запись данных Java Flight Recorder
- Автоматическое создание дампов памяти при критических ошибках

### Настройка Prometheus и Grafana

1. **Запуск инфраструктуры мониторинга:**
```bash
docker-compose up -d
```

Будут запущены:
- **Prometheus** на порту 9090
- **Grafana** на порту 3000 (учетные данные по умолчанию: admin/admin)
- **Jaeger** на порту 16686 для распределенного трейсинга

2. **Настройка сбора метрик:**
   - Конфигурационный файл `prometheus.yml` предварительно настроен
   - Prometheus автоматически собирает данные с эндпоинта `/actuator/prometheus`

3. **Настройка визуализации в Grafana:**
   - Выполните вход в веб-интерфейс Grafana
   - Добавьте источник данных типа Prometheus с адресом `http://prometheus:9090`
   - Создайте информационные панели на основе собранных метрик

### Распределенный трейсинг через OpenTelemetry

Система реализует распределенный трейсинг операций с отправкой данных в Jaeger.

**Трекируемые этапы обработки:**
- Получение HTML-контента с веб-страниц
- Анализ и извлечение контактной информации
- Сохранение данных о компании в хранилище
- Извлечение и обработка ссылок на странице

**Анализ трейсов:**
1. Откройте веб-интерфейс Jaeger: `http://localhost:16686`
2. Выберите сервис `company-crawler`
3. Воспользуйтесь функцией поиска трейсов
4. Изучите временные диаграммы выполнения операций

### Инструменты анализа производительности

**Подключение VisualVM:**
1. Установите VisualVM с официального сайта
2. Запустите приложение с активированным мониторингом
3. В VisualVM добавьте JMX-соединение с параметрами `localhost:9999`

**Анализ записей JFR:**
- Записи сохраняются в файл `./logs/recording.jfr`
- Для анализа используйте VisualVM или JDK Mission Control

### Тестирование производительности с JMH

**Запуск тестов производительности:**
```bash
mvn clean package
java -jar target/benchmarks.jar
```

Сравниваются различные подходы к парсингу данных:
- Классические циклы
- Использование Stream API
- Параллельные потоки
- Оптимизированные версии алгоритмов

### Дополнительная документация

Подробные руководства доступны в директории `docs/`:
- Руководство по настройке мониторинга
- Рекомендации по конфигурации JVM
- Шаблоны отчетов о производительности

## 11. Оптимизации производительности

### Выполненные улучшения:

1. **Устранение проблемы N+1 запросов:**
   - Применение `JOIN FETCH` в запросах к базе данных
   - Оптимизация загрузки связанных коллекций

2. **Оптимизация структуры базы данных:**
   - Создание индексов для часто используемых полей
   - Индексация коллекций телефонных номеров и адресов электронной почты

3. **Снижение нагрузки на память:**
   - Использование `LinkedHashSet` для исключения дубликатов
   - Оптимизация регулярных выражений для парсинга

4. **Обеспечение потокобезопасности:**
   - Применение специализированных потокобезопасных структур данных
   - Минимизация областей синхронизации